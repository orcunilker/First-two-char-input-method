{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the training data out of the whole book (book.txt)\n",
    "# Project -> Pr/Project and so on\n",
    "# saves it into \"book_processed_train.txt\"\n",
    "\n",
    "def prepare_text_for_training(text):\n",
    "    # Split text int owords\n",
    "    words = text.split()\n",
    "    \n",
    "    # Clean each word and bring it into form Pr/Project\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        clean_word = re.sub('[^a-zA-Z]', '', word) #only alphabetical\n",
    "        if len(clean_word) > 1:\n",
    "            processed_word = f\"{clean_word[:2]}/{clean_word}\"\n",
    "        elif len(clean_word) == 1:\n",
    "            processed_word = f\"{clean_word}/{clean_word}\"\n",
    "        if processed_word:  # only if existend\n",
    "            processed_words.append(processed_word)\n",
    "    \n",
    "    processed_words += \"\\n\"\n",
    "    return processed_words\n",
    "\n",
    "# Do it\n",
    "# Read\n",
    "with open('book.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "#Process\n",
    "processed_words = prepare_text_for_training(text)\n",
    "\n",
    "# Write\n",
    "with open('book_processed_train.txt', 'w') as file:\n",
    "    file.write('\\n'.join(processed_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text has been written to testing_input_processed_test.txt\n"
     ]
    }
   ],
   "source": [
    "# Prepares the test text that i took out of the book\n",
    "# Removes any non alphabetical characters and makes 2-grams of the words\n",
    "# for testing\n",
    "\n",
    "def generate2gramText(input_file, output_file):\n",
    "    # Read test input\n",
    "    with open(input_file, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = text.split()\n",
    "    \n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        clean_word = re.sub('[^a-zA-Z]', '', word)\n",
    "        if clean_word:\n",
    "            processed_words.append(clean_word[:2])\n",
    "    \n",
    "    # Join the processed words with a space\n",
    "    result = ' '.join(processed_words)\n",
    "    result += \"\\n\"\n",
    "    \n",
    "    # Write\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(result)\n",
    "\n",
    "\n",
    "input_file = 'testing_input.txt'\n",
    "output_file = 'testing_input_processed_test.txt'\n",
    "\n",
    "generate2gramText(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning dictionaries and corpora for vocabulary\n",
      "Reading corpus from book_processed_train.txt  done (90324 lines)\n",
      "Building dictionary index done!\n",
      "Creating tagging features (tag 1) done!\n",
      "Training local tag classifiers done!\n",
      "Printing model to train.model done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\"train-kytea -full book_processed_train.txt -nows -model train.model\", shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(result.stdout.decode('utf-8'))\n",
    "    print(result.stderr.decode('utf-8'))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e.stderr.decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = subprocess.run(\"kytea -model train.model -out tags < testing_input_processed_test.txt > test.out\", shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(result.stdout.decode('utf-8'))\n",
    "    print(result.stderr.decode('utf-8'))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e.stderr.decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness: 58.17%\n"
     ]
    }
   ],
   "source": [
    "# This compares the test text (ground-truth) to the kytea model result (from the 2grams)\n",
    "\n",
    "def read_clean_text(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text).lower() # Clean text\n",
    "    \n",
    "    words = cleaned_text.split() # Split to words\n",
    "    return words\n",
    "\n",
    "def compare_texts(input_file1, input_file2):\n",
    "    # Clean both result and ground-truth texts\n",
    "    words1 = read_clean_text(input_file1)\n",
    "    words2 = read_clean_text(input_file2)\n",
    "\n",
    "    matched_words = 0\n",
    "    if len(words1) == len(words2):\n",
    "        for i in range (0, len(words1)):\n",
    "            if words1[i] == words2[i]:\n",
    "                matched_words += 1\n",
    "    \n",
    "    percentage = 100 * matched_words/len(words1)\n",
    "    return percentage\n",
    "\n",
    "\n",
    "input_file1 = 'testing_input.txt'\n",
    "input_file2 = 'test.out'\n",
    "\n",
    "percentage = compare_texts(input_file1, input_file2)\n",
    "print(f\"Correctness: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
